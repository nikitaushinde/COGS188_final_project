{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'red'>Ignore this, I'm restarting...T-T <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_recipes(file_path):\n",
    "    \"\"\"Loads a recipe dataset from CSV or JSON.\"\"\"\n",
    "    if file_path.endswith('.csv'):\n",
    "        return pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.json'):\n",
    "        return pd.read_json(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Use CSV or JSON.\")\n",
    "\n",
    "def filter_recipes(recipes, available_ingredients, available_tools, max_time):\n",
    "    \"\"\"Filters recipes based on ingredients, kitchen tools, and time constraints.\"\"\"\n",
    "    filtered = []\n",
    "    \n",
    "    for _, recipe in recipes.iterrows():\n",
    "        required_ingredients = set(recipe['ingredients'].split(', '))\n",
    "        required_tools = set(recipe['tools'].split(', '))\n",
    "        prep_time = recipe['time']\n",
    "        \n",
    "        # Check ingredient availability\n",
    "        if not required_ingredients.issubset(set(available_ingredients)):\n",
    "            continue\n",
    "        \n",
    "        # Check kitchen tool availability\n",
    "        if not required_tools.issubset(set(available_tools)):\n",
    "            continue\n",
    "        \n",
    "        # Check time constraint\n",
    "        if prep_time > max_time:\n",
    "            continue\n",
    "        \n",
    "        filtered.append(recipe)\n",
    "    \n",
    "    return pd.DataFrame(filtered)\n",
    "\n",
    "# Example Usage:\n",
    "# recipes = load_recipes(\"recipes.csv\")\n",
    "# available_ingredients = [\"eggs\", \"flour\", \"milk\", \"butter\"]\n",
    "# available_tools = [\"oven\", \"whisk\"]\n",
    "# max_time = 30\n",
    "# filtered_recipes = filter_recipes(recipes, available_ingredients, available_tools, max_time)\n",
    "# print(filtered_recipes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PP_recipes.csv', 'nikita_playground.ipynb', 'test.json', 'RAW_recipes.csv', 'train.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())  # Check available files in the working directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP_recipes Columns: Index(['id', 'i', 'name_tokens', 'ingredient_tokens', 'steps_tokens',\n",
      "       'techniques', 'calorie_level', 'ingredient_ids'],\n",
      "      dtype='object')\n",
      "RAW_recipes Columns: Index(['name', 'id', 'minutes', 'contributor_id', 'submitted', 'tags',\n",
      "       'nutrition', 'n_steps', 'steps', 'description', 'ingredients',\n",
      "       'n_ingredients'],\n",
      "      dtype='object')\n",
      "Test_Recipes Columns: Index(['id', 'ingredients'], dtype='object')\n",
      "Train_Recipes Columns: Index(['id', 'cuisine', 'ingredients'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets from local files\n",
    "df1 = pd.read_csv(\"PP_recipes.csv\")\n",
    "df2 = pd.read_csv(\"RAW_recipes.csv\")\n",
    "df3 = pd.read_json(\"test.json\")\n",
    "df4 = pd.read_json(\"train.json\")\n",
    "\n",
    "# Store datasets in a dictionary for easier access\n",
    "datasets = {\n",
    "    \"PP_recipes\": df1,\n",
    "    \"RAW_recipes\": df2,\n",
    "    \"Test_Recipes\": df3,\n",
    "    \"Train_Recipes\": df4\n",
    "}\n",
    "\n",
    "# Print dataset column names to understand their structure\n",
    "for name, df in datasets.items():\n",
    "    print(f\"{name} Columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ After handling missing values:\n",
      "name              0\n",
      "id                0\n",
      "minutes           0\n",
      "contributor_id    0\n",
      "submitted         0\n",
      "tags              0\n",
      "nutrition         0\n",
      "n_steps           0\n",
      "steps             0\n",
      "description       0\n",
      "ingredients       0\n",
      "n_ingredients     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v7/ql09t2fn277_jnyd8yjb2v880000gq/T/ipykernel_89601/1016164666.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  datasets[\"RAW_recipes\"][\"description\"].fillna(\"No description available\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing 'name' (since it's crucial)\n",
    "datasets[\"RAW_recipes\"].dropna(subset=[\"name\"], inplace=True)\n",
    "\n",
    "# Fill missing descriptions with placeholder text\n",
    "datasets[\"RAW_recipes\"][\"description\"].fillna(\"No description available\", inplace=True)\n",
    "\n",
    "# Verify missing values are handled\n",
    "print(\"\\n‚úÖ After handling missing values:\")\n",
    "print(datasets[\"RAW_recipes\"].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking missing values in PP_recipes:\n",
      "id                   0\n",
      "i                    0\n",
      "name_tokens          0\n",
      "ingredient_tokens    0\n",
      "steps_tokens         0\n",
      "techniques           0\n",
      "calorie_level        0\n",
      "ingredient_ids       0\n",
      "dtype: int64\n",
      "üîç Checking missing values in RAW_recipes:\n",
      "name              0\n",
      "id                0\n",
      "minutes           0\n",
      "contributor_id    0\n",
      "submitted         0\n",
      "tags              0\n",
      "nutrition         0\n",
      "n_steps           0\n",
      "steps             0\n",
      "description       0\n",
      "ingredients       0\n",
      "n_ingredients     0\n",
      "dtype: int64\n",
      "üîç Checking missing values in Test_Recipes:\n",
      "id             0\n",
      "ingredients    0\n",
      "dtype: int64\n",
      "üîç Checking missing values in Train_Recipes:\n",
      "id             0\n",
      "cuisine        0\n",
      "ingredients    0\n",
      "dtype: int64\n",
      "‚úÖ Cleaned PP_recipes:        id       i                                        name_tokens  \\\n",
      "0  424415      23  [40480, 37229, 2911, 1019, 249, 6878, 6878, 28...   \n",
      "1  146223   96900       [40480, 18376, 7056, 246, 1531, 2032, 40481]   \n",
      "2  312329  120056     [40480, 21044, 16954, 8294, 556, 10837, 40481]   \n",
      "3   74301  168258                       [40480, 10025, 31156, 40481]   \n",
      "4   76272  109030  [40480, 17841, 252, 782, 2373, 1641, 2373, 252...   \n",
      "\n",
      "                                   ingredient_tokens  \\\n",
      "0  [[2911, 1019, 249, 6878], [1353], [6953], [153...   \n",
      "1  [[17918], [25916], [2507, 6444], [8467, 1179],...   \n",
      "2  [[5867, 24176], [1353], [6953], [1301, 11332],...   \n",
      "3  [[1270, 1645, 28447], [21601], [27952, 29471, ...   \n",
      "4  [[1430, 11434], [1430, 17027], [1615, 23, 695,...   \n",
      "\n",
      "                                        steps_tokens  \\\n",
      "0  [40480, 40482, 21662, 481, 6878, 500, 246, 161...   \n",
      "1  [40480, 40482, 729, 2525, 10906, 485, 43, 8393...   \n",
      "2  [40480, 40482, 8240, 481, 24176, 296, 1353, 66...   \n",
      "3  [40480, 40482, 5539, 21601, 1073, 903, 2324, 4...   \n",
      "4  [40480, 40482, 14046, 1430, 11434, 488, 17027,...   \n",
      "\n",
      "                                          techniques  calorie_level  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...              0   \n",
      "1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...              0   \n",
      "2  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...              1   \n",
      "3  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              0   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...              0   \n",
      "\n",
      "                                      ingredient_ids  \n",
      "0                      [389, 7655, 6270, 1527, 3406]  \n",
      "1  [2683, 4969, 800, 5298, 840, 2499, 6632, 7022,...  \n",
      "2  [1257, 7655, 6270, 590, 5024, 1119, 4883, 6696...  \n",
      "3   [7940, 3609, 7060, 6265, 1170, 6654, 5003, 3561]  \n",
      "4                            [3484, 6324, 7594, 243]  \n",
      "‚úÖ Cleaned RAW_recipes:                                          name      id  minutes  \\\n",
      "0  arriba   baked winter squash mexican style  137739       55   \n",
      "1            a bit different  breakfast pizza   31490       30   \n",
      "2                   all in the kitchen  chili  112140      130   \n",
      "3                          alouette  potatoes   59389       45   \n",
      "4          amish  tomato ketchup  for canning   44061      190   \n",
      "\n",
      "   contributor_id   submitted  \\\n",
      "0           47892  2005-09-16   \n",
      "1           26278  2002-06-17   \n",
      "2          196586  2005-02-25   \n",
      "3           68585  2003-04-14   \n",
      "4           41706  2002-10-25   \n",
      "\n",
      "                                                tags  \\\n",
      "0  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
      "1  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
      "2  ['time-to-make', 'course', 'preparation', 'mai...   \n",
      "3  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
      "4  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
      "\n",
      "                                    nutrition  n_steps  \\\n",
      "0       [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
      "1   [173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]        9   \n",
      "2  [269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]        6   \n",
      "3   [368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]       11   \n",
      "4   [352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]        5   \n",
      "\n",
      "                                               steps  \\\n",
      "0  ['make a choice and proceed with recipe', 'dep...   \n",
      "1  ['preheat oven to 425 degrees f', 'press dough...   \n",
      "2  ['brown ground beef in large pot', 'add choppe...   \n",
      "3  ['place potatoes in a large pot of lightly sal...   \n",
      "4  ['mix all ingredients& boil for 2 1 / 2 hours ...   \n",
      "\n",
      "                                         description  \\\n",
      "0  autumn is my favorite time of year to cook! th...   \n",
      "1  this recipe calls for the crust to be prebaked...   \n",
      "2  this modified version of 'mom's' chili was a h...   \n",
      "3  this is a super easy, great tasting, make ahea...   \n",
      "4  my dh's amish mother raised him on this recipe...   \n",
      "\n",
      "                                         ingredients  n_ingredients  \n",
      "0  {'mixed spice', ['winter squash', 'butter', 'h...              7  \n",
      "1  {'sausage patty', 'milk', 'salt and pepper', '...              6  \n",
      "2  {'cheddar cheese'], 'rotel tomatoes', 'diced t...             13  \n",
      "3  {'parsley', 'red bell pepper', 'new potatoes',...             11  \n",
      "4  {['tomato juice', 'dry mustard'], 'cinnamon oi...              8  \n",
      "‚úÖ Cleaned Test_Recipes:       id                                        ingredients\n",
      "0  18009  {milk, white sugar, all-purpose flour, baking ...\n",
      "1  28583  {cream of tartar, sugar, corn starch, toasted ...\n",
      "2  41580  {fronds, cuban peppers, olive oil, sausage lin...\n",
      "3  29752  {lump crab meat, paprika, browning, ham, dried...\n",
      "4  35687  {leeks, sausage casings, extra-virgin olive oi...\n",
      "‚úÖ Cleaned Train_Recipes:       id      cuisine                                        ingredients\n",
      "0  10259        greek  {seasoning, feta cheese crumbles, garlic, garb...\n",
      "1  25693  southern_us  {green tomatoes, tomatoes, milk, plain flour, ...\n",
      "2  20130     filipino  {butter, yellow onion, salt, green chilies, ga...\n",
      "3  22213       indian                {wheat, salt, vegetable oil, water}\n",
      "4  13162       indian  {chili powder, boneless chicken skinless thigh...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to clean and preprocess the ingredients column\n",
    "def clean_ingredients(ingredients):\n",
    "    \"\"\"Convert ingredients to lowercase, remove special characters, and format as a set.\"\"\"\n",
    "    if isinstance(ingredients, list):\n",
    "        return set([ingredient.lower().strip() for ingredient in ingredients])\n",
    "    elif isinstance(ingredients, str):\n",
    "        return set([ingredient.lower().strip() for ingredient in ingredients.split(',')])\n",
    "    else:\n",
    "        return set()\n",
    "\n",
    "# Apply cleaning to each dataset\n",
    "for name, df in datasets.items():\n",
    "    if \"ingredients\" in df.columns:\n",
    "        df[\"ingredients\"] = df[\"ingredients\"].apply(clean_ingredients)\n",
    "\n",
    "# Handle missing values\n",
    "for name, df in datasets.items():\n",
    "    print(f\"üîç Checking missing values in {name}:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    # Fill or drop missing values if necessary\n",
    "    df.fillna(\"\", inplace=True)  # Replace NaN with empty strings for text fields\n",
    "\n",
    "# Check if datasets are now clean\n",
    "for name, df in datasets.items():\n",
    "    print(f\"‚úÖ Cleaned {name}: {df.head()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Standardized dataset: PP_recipes (Time column: 'minutes')\n",
      "‚úÖ Standardized dataset: RAW_recipes (Time column: 'minutes')\n",
      "‚úÖ Standardized dataset: Test_Recipes (Time column: 'minutes')\n",
      "‚úÖ Standardized dataset: Train_Recipes (Time column: 'minutes')\n",
      "\n",
      "üîç Checking dataset: PP_recipes\n",
      "       id       i                                        name_tokens  \\\n",
      "0  424415      23  [40480, 37229, 2911, 1019, 249, 6878, 6878, 28...   \n",
      "1  146223   96900       [40480, 18376, 7056, 246, 1531, 2032, 40481]   \n",
      "2  312329  120056     [40480, 21044, 16954, 8294, 556, 10837, 40481]   \n",
      "3   74301  168258                       [40480, 10025, 31156, 40481]   \n",
      "4   76272  109030  [40480, 17841, 252, 782, 2373, 1641, 2373, 252...   \n",
      "\n",
      "                                   ingredient_tokens  \\\n",
      "0  [[2911, 1019, 249, 6878], [1353], [6953], [153...   \n",
      "1  [[17918], [25916], [2507, 6444], [8467, 1179],...   \n",
      "2  [[5867, 24176], [1353], [6953], [1301, 11332],...   \n",
      "3  [[1270, 1645, 28447], [21601], [27952, 29471, ...   \n",
      "4  [[1430, 11434], [1430, 17027], [1615, 23, 695,...   \n",
      "\n",
      "                                        steps_tokens  \\\n",
      "0  [40480, 40482, 21662, 481, 6878, 500, 246, 161...   \n",
      "1  [40480, 40482, 729, 2525, 10906, 485, 43, 8393...   \n",
      "2  [40480, 40482, 8240, 481, 24176, 296, 1353, 66...   \n",
      "3  [40480, 40482, 5539, 21601, 1073, 903, 2324, 4...   \n",
      "4  [40480, 40482, 14046, 1430, 11434, 488, 17027,...   \n",
      "\n",
      "                                          techniques  calorie_level  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...              0   \n",
      "1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...              0   \n",
      "2  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...              1   \n",
      "3  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              0   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...              0   \n",
      "\n",
      "                                      ingredient_ids  minutes  \n",
      "0                      [389, 7655, 6270, 1527, 3406]        0  \n",
      "1  [2683, 4969, 800, 5298, 840, 2499, 6632, 7022,...        0  \n",
      "2  [1257, 7655, 6270, 590, 5024, 1119, 4883, 6696...        0  \n",
      "3   [7940, 3609, 7060, 6265, 1170, 6654, 5003, 3561]        0  \n",
      "4                            [3484, 6324, 7594, 243]        0  \n",
      "\n",
      "üîç Checking dataset: RAW_recipes\n",
      "                                         name      id  minutes  \\\n",
      "0  arriba   baked winter squash mexican style  137739       55   \n",
      "1            a bit different  breakfast pizza   31490       30   \n",
      "2                   all in the kitchen  chili  112140      130   \n",
      "3                          alouette  potatoes   59389       45   \n",
      "4          amish  tomato ketchup  for canning   44061      190   \n",
      "\n",
      "   contributor_id   submitted  \\\n",
      "0           47892  2005-09-16   \n",
      "1           26278  2002-06-17   \n",
      "2          196586  2005-02-25   \n",
      "3           68585  2003-04-14   \n",
      "4           41706  2002-10-25   \n",
      "\n",
      "                                                tags  \\\n",
      "0  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
      "1  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
      "2  ['time-to-make', 'course', 'preparation', 'mai...   \n",
      "3  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
      "4  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
      "\n",
      "                                    nutrition  n_steps  \\\n",
      "0       [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
      "1   [173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]        9   \n",
      "2  [269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]        6   \n",
      "3   [368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]       11   \n",
      "4   [352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]        5   \n",
      "\n",
      "                                               steps  \\\n",
      "0  ['make a choice and proceed with recipe', 'dep...   \n",
      "1  ['preheat oven to 425 degrees f', 'press dough...   \n",
      "2  ['brown ground beef in large pot', 'add choppe...   \n",
      "3  ['place potatoes in a large pot of lightly sal...   \n",
      "4  ['mix all ingredients& boil for 2 1 / 2 hours ...   \n",
      "\n",
      "                                         description  \\\n",
      "0  autumn is my favorite time of year to cook! th...   \n",
      "1  this recipe calls for the crust to be prebaked...   \n",
      "2  this modified version of 'mom's' chili was a h...   \n",
      "3  this is a super easy, great tasting, make ahea...   \n",
      "4  my dh's amish mother raised him on this recipe...   \n",
      "\n",
      "                                         ingredients  n_ingredients  \n",
      "0  {'mixed spice', ['winter squash', 'butter', 'h...              7  \n",
      "1  {'sausage patty', 'milk', 'salt and pepper', '...              6  \n",
      "2  {'cheddar cheese'], 'rotel tomatoes', 'diced t...             13  \n",
      "3  {'parsley', 'red bell pepper', 'new potatoes',...             11  \n",
      "4  {['tomato juice', 'dry mustard'], 'cinnamon oi...              8  \n",
      "\n",
      "üîç Checking dataset: Test_Recipes\n",
      "      id                                        ingredients  minutes\n",
      "0  18009  {milk, white sugar, all-purpose flour, baking ...        0\n",
      "1  28583  {cream of tartar, sugar, corn starch, toasted ...        0\n",
      "2  41580  {fronds, cuban peppers, olive oil, sausage lin...        0\n",
      "3  29752  {lump crab meat, paprika, browning, ham, dried...        0\n",
      "4  35687  {leeks, sausage casings, extra-virgin olive oi...        0\n",
      "\n",
      "üîç Checking dataset: Train_Recipes\n",
      "      id      cuisine                                        ingredients  \\\n",
      "0  10259        greek  {seasoning, feta cheese crumbles, garlic, garb...   \n",
      "1  25693  southern_us  {green tomatoes, tomatoes, milk, plain flour, ...   \n",
      "2  20130     filipino  {butter, yellow onion, salt, green chilies, ga...   \n",
      "3  22213       indian                {wheat, salt, vegetable oil, water}   \n",
      "4  13162       indian  {chili powder, boneless chicken skinless thigh...   \n",
      "\n",
      "   minutes  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n",
      "‚úÖ Verified: PP_recipes has 'minutes' as numeric.\n",
      "‚úÖ Verified: RAW_recipes has 'minutes' as numeric.\n",
      "‚úÖ Verified: Test_Recipes has 'minutes' as numeric.\n",
      "‚úÖ Verified: Train_Recipes has 'minutes' as numeric.\n",
      "\n",
      "üîç Dataset: PP_recipes - Columns: ['id', 'i', 'name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'calorie_level', 'ingredient_ids', 'minutes']\n",
      "\n",
      "üîç Dataset: RAW_recipes - Columns: ['name', 'id', 'minutes', 'contributor_id', 'submitted', 'tags', 'nutrition', 'n_steps', 'steps', 'description', 'ingredients', 'n_ingredients']\n",
      "\n",
      "üîç Dataset: Test_Recipes - Columns: ['id', 'ingredients', 'minutes']\n",
      "\n",
      "üîç Dataset: Train_Recipes - Columns: ['id', 'cuisine', 'ingredients', 'minutes']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'minutes'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/var/folders/v7/ql09t2fn277_jnyd8yjb2v880000gq/T/ipykernel_89601/4257508353.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    196\u001b[39m available_ingredients = {\u001b[33m\"eggs\"\u001b[39m, \u001b[33m\"flour\"\u001b[39m, \u001b[33m\"milk\"\u001b[39m, \u001b[33m\"butter\"\u001b[39m, \u001b[33m\"chocolate\"\u001b[39m}\n\u001b[32m    197\u001b[39m available_tools = {\u001b[33m\"oven\"\u001b[39m, \u001b[33m\"whisk\"\u001b[39m}\n\u001b[32m    198\u001b[39m max_time = \u001b[32m30\u001b[39m\n\u001b[32m    199\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m print(generate_recipe(available_ingredients, available_tools, max_time, datasets))\n",
      "\u001b[32m/var/folders/v7/ql09t2fn277_jnyd8yjb2v880000gq/T/ipykernel_89601/4257508353.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(available_ingredients, available_tools, max_time, datasets)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m generate_recipe(available_ingredients, available_tools, max_time, datasets):\n\u001b[32m    162\u001b[39m     \u001b[33m\"\"\"Generates a new recipe based on available ingredients and constraints.\"\"\"\u001b[39m\n\u001b[32m    163\u001b[39m \n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Step 1: Automatically pick the best dataset\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     dataset = get_best_dataset(datasets, available_ingredients, available_tools, max_time)\n\u001b[32m    166\u001b[39m \n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dataset \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"‚ùå No valid dataset found.\"\u001b[39m\n",
      "\u001b[32m/var/folders/v7/ql09t2fn277_jnyd8yjb2v880000gq/T/ipykernel_89601/4257508353.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(datasets, available_ingredients, available_tools, max_time)\u001b[39m\n\u001b[32m     70\u001b[39m \n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, dataset \u001b[38;5;28;01min\u001b[39;00m datasets.items():\n\u001b[32m     72\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"ingredients\"\u001b[39m \u001b[38;5;28;01min\u001b[39;00m dataset.columns:\n\u001b[32m     73\u001b[39m             \u001b[38;5;66;03m# Count recipes that match the ingredient and time constraints\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m             filtered = filter_recipes(dataset, available_ingredients, available_tools, max_time)\n\u001b[32m     75\u001b[39m             dataset_scores[name] = len(filtered)\n\u001b[32m     76\u001b[39m \n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m dataset_scores \u001b[38;5;28;01mor\u001b[39;00m max(dataset_scores.values()) == \u001b[32m0\u001b[39m:\n",
      "\u001b[32m/var/folders/v7/ql09t2fn277_jnyd8yjb2v880000gq/T/ipykernel_89601/4257508353.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(recipes, available_ingredients, available_tools, max_time)\u001b[39m\n\u001b[32m    151\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    152\u001b[39m \n\u001b[32m    153\u001b[39m         filtered.append(recipe)\n\u001b[32m    154\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(filtered).sort_values(by=\u001b[33m\"minutes\"\u001b[39m, ascending=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    156\u001b[39m \n\u001b[32m    157\u001b[39m \n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# **Final Fix: Only sort if time_col exists**\u001b[39;00m\n",
      "\u001b[32m~/Desktop/A4/venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7185\u001b[39m             )\n\u001b[32m   7186\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m len(by):\n\u001b[32m   7187\u001b[39m             \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[32m   7188\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m7189\u001b[39m             k = self._get_label_or_level_values(by[\u001b[32m0\u001b[39m], axis=axis)\n\u001b[32m   7190\u001b[39m \n\u001b[32m   7191\u001b[39m             \u001b[38;5;66;03m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[32m   7192\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m~/Desktop/A4/venv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'minutes'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "def standardize_datasets(datasets):\n",
    "    \"\"\"Ensure all datasets have a 'minutes' column for consistency.\"\"\"\n",
    "    \n",
    "    for name, df in datasets.items():\n",
    "        # Identify possible time-related columns\n",
    "        possible_time_cols = [\"minutes\", \"time\", \"cook_time\", \"prep_time\"]\n",
    "\n",
    "        # Find an existing time column\n",
    "        time_col = next((col for col in possible_time_cols if col in df.columns), None)\n",
    "\n",
    "        if time_col:\n",
    "            # Rename the found column to 'minutes' for consistency\n",
    "            df.rename(columns={time_col: \"minutes\"}, inplace=True)\n",
    "        else:\n",
    "            # If no time-related column exists, create 'minutes' with default 0\n",
    "            df[\"minutes\"] = 0\n",
    "\n",
    "        # Print confirmation\n",
    "        print(f\"‚úÖ Standardized dataset: {name} (Time column: 'minutes')\")\n",
    "\n",
    "    return datasets\n",
    "\n",
    "# Run this before filtering or generating recipes\n",
    "datasets = standardize_datasets(datasets)\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\nüîç Checking dataset: {name}\")\n",
    "    print(df.head())  # Show sample rows\n",
    "    if \"minutes\" not in df.columns:\n",
    "        print(f\"‚ùå ERROR: 'minutes' column is missing from {name}!\")\n",
    "\n",
    "def enforce_minutes_column(datasets):\n",
    "    \"\"\"Ensure all datasets contain a 'minutes' column as an integer.\"\"\"\n",
    "    for name, df in datasets.items():\n",
    "        if \"minutes\" not in df.columns:\n",
    "            print(f\"‚ö†Ô∏è WARNING: 'minutes' missing in {name}. Adding default values.\")\n",
    "            df[\"minutes\"] = 0  # Default value\n",
    "        else:\n",
    "            # Convert to integer type if it exists\n",
    "            df[\"minutes\"] = pd.to_numeric(df[\"minutes\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "    return datasets\n",
    "\n",
    "# Run before filtering\n",
    "datasets = enforce_minutes_column(datasets)\n",
    "\n",
    "def ensure_minutes_column(datasets):\n",
    "    \"\"\"Forces every dataset to have a numeric 'minutes' column to prevent errors.\"\"\"\n",
    "    for name, df in datasets.items():\n",
    "        if \"minutes\" not in df.columns:\n",
    "            print(f\"‚ö†Ô∏è Fixing: Adding 'minutes' column to {name}.\")\n",
    "            df[\"minutes\"] = 0  # Default to 0 minutes if missing\n",
    "        else:\n",
    "            # Convert to integer to avoid issues\n",
    "            df[\"minutes\"] = pd.to_numeric(df[\"minutes\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "        print(f\"‚úÖ Verified: {name} has 'minutes' as numeric.\")\n",
    "\n",
    "    return datasets\n",
    "\n",
    "# Apply before filtering\n",
    "datasets = ensure_minutes_column(datasets)\n",
    "\n",
    "def get_best_dataset(datasets, available_ingredients, available_tools, max_time):\n",
    "    \"\"\"Automatically selects the dataset with the most matching recipes.\"\"\"\n",
    "    dataset_scores = {}\n",
    "\n",
    "    for name, dataset in datasets.items():\n",
    "        if \"ingredients\" in dataset.columns:\n",
    "            # Count recipes that match the ingredient and time constraints\n",
    "            filtered = filter_recipes(dataset, available_ingredients, available_tools, max_time)\n",
    "            dataset_scores[name] = len(filtered)\n",
    "\n",
    "    if not dataset_scores or max(dataset_scores.values()) == 0:\n",
    "        print(\"‚ùå No suitable dataset found.\")\n",
    "        return None\n",
    "\n",
    "    # Choose the dataset with the most valid recipes\n",
    "    best_dataset = max(dataset_scores, key=dataset_scores.get)\n",
    "\n",
    "    print(f\"\\n‚úÖ Using Best Dataset: {best_dataset} ({dataset_scores[best_dataset]} matching recipes)\")\n",
    "    return datasets[best_dataset]\n",
    "\n",
    "\n",
    "# Debug: Check all dataset columns before filtering\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\nüîç Dataset: {name} - Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "\n",
    "# def filter_recipes(recipes, available_ingredients, available_tools, max_time):\n",
    "#     \"\"\"Filters recipes based on available ingredients, kitchen tools, and time constraints.\"\"\"\n",
    "#     if recipes is None or recipes.empty:\n",
    "#         print(\"‚ùå No recipes available to filter.\")\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "#     # Find the correct time-related column dynamically\n",
    "#     possible_time_cols = [\"minutes\", \"time\", \"cook_time\"]\n",
    "#     time_col = next((col for col in possible_time_cols if col in recipes.columns), None)\n",
    "\n",
    "#     if time_col is None:\n",
    "#         print(\"‚ö†Ô∏è No time-related column found. Skipping time filtering.\")\n",
    "\n",
    "#     filtered = []\n",
    "\n",
    "#     for _, recipe in recipes.iterrows():\n",
    "#         required_ingredients = recipe[\"ingredients\"]\n",
    "\n",
    "#         # Ensure 'tools' column exists\n",
    "#         required_tools = set(recipe.get(\"tools\", \"\").split(\", \")) if \"tools\" in recipes.columns else set()\n",
    "\n",
    "#         # Get preparation time if available\n",
    "#         prep_time = int(recipe.get(time_col, 0)) if time_col else 0\n",
    "\n",
    "#         # Check conditions\n",
    "#         if not required_ingredients.issubset(set(available_ingredients)):\n",
    "#             continue\n",
    "#         if \"tools\" in recipes.columns and not required_tools.issubset(set(available_tools)):\n",
    "#             continue\n",
    "#         if time_col and prep_time > max_time:\n",
    "#             continue\n",
    "\n",
    "#         filtered.append(recipe)\n",
    "def filter_recipes(recipes, available_ingredients, available_tools, max_time):\n",
    "    \"\"\"Filters recipes based on available ingredients, kitchen tools, and time constraints.\"\"\"\n",
    "    if recipes is None or recipes.empty:\n",
    "        print(\"‚ùå No recipes available to filter.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # üîπ Ensure 'minutes' still exists before filtering\n",
    "    if \"minutes\" not in recipes.columns:\n",
    "        print(\"‚ö†Ô∏è WARNING: 'minutes' column is missing! Re-adding it with default value 0.\")\n",
    "        recipes[\"minutes\"] = 0  # Default value\n",
    "\n",
    "    # Now continue filtering as usual\n",
    "    filtered = []\n",
    "\n",
    "    for _, recipe in recipes.iterrows():\n",
    "        required_ingredients = recipe[\"ingredients\"]\n",
    "        required_tools = set(recipe.get(\"tools\", \"\").split(\", \")) if \"tools\" in recipes.columns else set()\n",
    "        prep_time = int(recipe[\"minutes\"])  # Now guaranteed to exist\n",
    "\n",
    "        # Apply filters\n",
    "        if not required_ingredients.issubset(set(available_ingredients)):\n",
    "            continue\n",
    "        if \"tools\" in recipes.columns and not required_tools.issubset(set(available_tools)):\n",
    "            continue\n",
    "        if prep_time > max_time:\n",
    "            continue\n",
    "\n",
    "        filtered.append(recipe)\n",
    "\n",
    "    return pd.DataFrame(filtered).sort_values(by=\"minutes\", ascending=True)\n",
    "\n",
    "\n",
    "    # **Final Fix: Only sort if time_col exists**\n",
    "    return pd.DataFrame(filtered).sort_values(by=time_col, ascending=True) if time_col else pd.DataFrame(filtered)\n",
    "\n",
    "def generate_recipe(available_ingredients, available_tools, max_time, datasets):\n",
    "    \"\"\"Generates a new recipe based on available ingredients and constraints.\"\"\"\n",
    "\n",
    "    # Step 1: Automatically pick the best dataset\n",
    "    dataset = get_best_dataset(datasets, available_ingredients, available_tools, max_time)\n",
    "\n",
    "    if dataset is None:\n",
    "        return \"‚ùå No valid dataset found.\"\n",
    "\n",
    "    # Step 2: Filter recipes\n",
    "    filtered = filter_recipes(dataset, available_ingredients, available_tools, max_time)\n",
    "\n",
    "    if filtered.empty:\n",
    "        return \"‚ùå No valid recipes found.\"\n",
    "\n",
    "    # Step 3: Select a random recipe\n",
    "    selected_recipe = filtered.sample(1).iloc[0]\n",
    "\n",
    "    # Step 4: Randomly swap or add an ingredient\n",
    "    ingredient_list = list(selected_recipe[\"ingredients\"])\n",
    "    if len(ingredient_list) > 2:\n",
    "        ingredient_list[random.randint(0, len(ingredient_list) - 1)] = random.choice(list(available_ingredients))\n",
    "\n",
    "    # Step 5: Format output (Fixing time_col lookup)\n",
    "    time_col = next((col for col in [\"minutes\", \"time\", \"cook_time\"] if col in selected_recipe.index), None)\n",
    "\n",
    "    return f\"\"\"\n",
    "    üçΩÔ∏è **Generated Recipe:** {selected_recipe['name']} (Modified)\n",
    "    üïí **Time:** {selected_recipe.get(time_col, 'Unknown')} minutes\n",
    "    üõ†Ô∏è **Tools:** {', '.join(available_tools)}\n",
    "    üìù **Ingredients:** {', '.join(ingredient_list)}\n",
    "    üìú **Steps:** {selected_recipe.get('steps', 'No steps available')}\n",
    "    \"\"\"\n",
    "\n",
    "# Example Usage\n",
    "available_ingredients = {\"eggs\", \"flour\", \"milk\", \"butter\", \"chocolate\"}\n",
    "available_tools = {\"oven\", \"whisk\"}\n",
    "max_time = 30\n",
    "\n",
    "print(generate_recipe(available_ingredients, available_tools, max_time, datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET: https://www.kaggle.com/datasets/shuyangli94/food-com-recipes-and-user-interactions\n",
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "# !pip install kagglehub\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path1 = \"PP_recipes.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df1 = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"shuyangli94/food-com-recipes-and-user-interactions\",\n",
    "  file_path1\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET: https://www.kaggle.com/datasets/shuyangli94/food-com-recipes-and-user-interactions\n",
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "# !pip install kagglehub\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path2 = \"RAW_recipes.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df2 = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"shuyangli94/food-com-recipes-and-user-interactions\",\n",
    "  file_path2\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET: https://www.kaggle.com/datasets/kaggle/recipe-ingredients-dataset\n",
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path3 = \"test.json\"\n",
    "\n",
    "# Load the latest version\n",
    "df3 = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"kaggle/recipe-ingredients-dataset\",\n",
    "  file_path3,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET: https://www.kaggle.com/datasets/kaggle/recipe-ingredients-dataset\n",
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path4 = \"train.json\"\n",
    "\n",
    "# Load the latest version\n",
    "df4 = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"kaggle/recipe-ingredients-dataset\",\n",
    "  file_path4,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df4.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "def get_best_dataset(datasets, available_ingredients, available_tools, max_time):\n",
    "    \"\"\"Automatically selects the dataset with the most matching recipes.\"\"\"\n",
    "    dataset_scores = {}\n",
    "\n",
    "    for name, dataset in datasets.items():\n",
    "        if \"ingredients\" in dataset.columns:\n",
    "            # Count recipes that match the ingredient and time constraints\n",
    "            filtered = filter_recipes(dataset, available_ingredients, available_tools, max_time)\n",
    "            dataset_scores[name] = len(filtered)\n",
    "\n",
    "    if not dataset_scores or max(dataset_scores.values()) == 0:\n",
    "        print(\"‚ùå No suitable dataset found.\")\n",
    "        return None\n",
    "\n",
    "    # Choose the dataset with the most valid recipes\n",
    "    best_dataset = max(dataset_scores, key=dataset_scores.get)\n",
    "\n",
    "    print(f\"\\n‚úÖ Using Best Dataset: {best_dataset} ({dataset_scores[best_dataset]} matching recipes)\")\n",
    "    return datasets[best_dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_recipes(recipes, available_ingredients, available_tools, max_time):\n",
    "    \"\"\"Filters recipes based on available ingredients, kitchen tools, and time constraints.\"\"\"\n",
    "    if recipes is None or recipes.empty:\n",
    "        print(\"‚ùå No recipes available to filter.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Find the correct time-related column dynamically\n",
    "    time_col = next((col for col in [\"minutes\", \"time\", \"cook_time\"] if col in recipes.columns), None)\n",
    "\n",
    "    if time_col is None:\n",
    "        print(\"‚ö†Ô∏è No time-related column found. Skipping time filtering.\")\n",
    "\n",
    "    filtered = []\n",
    "\n",
    "    for _, recipe in recipes.iterrows():\n",
    "        required_ingredients = recipe[\"ingredients\"]\n",
    "\n",
    "        # Ensure 'tools' column exists\n",
    "        required_tools = set(recipe.get(\"tools\", \"\").split(\", \")) if \"tools\" in recipes.columns else set()\n",
    "\n",
    "        # Get preparation time if available\n",
    "        prep_time = int(recipe.get(time_col, 0)) if time_col else 0\n",
    "\n",
    "        # Check conditions\n",
    "        if not required_ingredients.issubset(set(available_ingredients)):\n",
    "            continue\n",
    "        if \"tools\" in recipes.columns and not required_tools.issubset(set(available_tools)):\n",
    "            continue\n",
    "        if time_col and prep_time > max_time:\n",
    "            continue\n",
    "\n",
    "        filtered.append(recipe)\n",
    "\n",
    "    return pd.DataFrame(filtered).sort_values(by=time_col, ascending=True) if time_col else pd.DataFrame(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recipe(available_ingredients, available_tools, max_time, datasets):\n",
    "    \"\"\"Generates a new recipe based on available ingredients and constraints.\"\"\"\n",
    "\n",
    "    # Step 1: Automatically pick the best dataset\n",
    "    dataset = get_best_dataset(datasets, available_ingredients, available_tools, max_time)\n",
    "\n",
    "    if dataset is None:\n",
    "        return \"‚ùå No valid dataset found.\"\n",
    "\n",
    "    # Step 2: Filter recipes\n",
    "    filtered = filter_recipes(dataset, available_ingredients, available_tools, max_time)\n",
    "\n",
    "    if filtered.empty:\n",
    "        return \"‚ùå No valid recipes found.\"\n",
    "\n",
    "    # Step 3: Select a random recipe\n",
    "    selected_recipe = filtered.sample(1).iloc[0]\n",
    "\n",
    "    # Step 4: Randomly swap or add an ingredient\n",
    "    ingredient_list = list(selected_recipe[\"ingredients\"])\n",
    "    if len(ingredient_list) > 2:\n",
    "        ingredient_list[random.randint(0, len(ingredient_list) - 1)] = random.choice(list(available_ingredients))\n",
    "\n",
    "    # Step 5: Format output\n",
    "    return f\"\"\"\n",
    "    üçΩÔ∏è **Generated Recipe:** {selected_recipe['name']} (Modified)\n",
    "    üïí **Time:** {selected_recipe.get(time_col, 'Unknown')} minutes\n",
    "    üõ†Ô∏è **Tools:** {', '.join(available_tools)}\n",
    "    üìù **Ingredients:** {', '.join(ingredient_list)}\n",
    "    üìú **Steps:** {selected_recipe.get('steps', 'No steps available')}\n",
    "    \"\"\"\n",
    "\n",
    "# Example Usage\n",
    "available_ingredients = {\"eggs\", \"flour\", \"milk\", \"butter\", \"chocolate\"}\n",
    "available_tools = {\"oven\", \"whisk\"}\n",
    "max_time = 30\n",
    "\n",
    "print(generate_recipe(available_ingredients, available_tools, max_time, datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_recipes(recipes, available_ingredients, available_tools, max_time):\n",
    "    \"\"\"Filters recipes based on available ingredients, kitchen tools, and time constraints.\"\"\"\n",
    "    if recipes is None or recipes.empty:\n",
    "        print(\"‚ùå No recipes available to filter.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    time_col = \"minutes\" if \"minutes\" in recipes.columns else None\n",
    "\n",
    "    if time_col is None:\n",
    "        print(\"‚ùå No time-related column found. Skipping time filtering.\")\n",
    "\n",
    "    filtered = []\n",
    "\n",
    "    for _, recipe in recipes.iterrows():\n",
    "        required_ingredients = recipe[\"ingredients\"]\n",
    "\n",
    "        # Ensure 'tools' column exists\n",
    "        required_tools = set(recipe[\"tools\"].split(\", \")) if \"tools\" in recipes.columns else set()\n",
    "\n",
    "        # Get preparation time\n",
    "        prep_time = int(recipe[time_col]) if time_col else 0\n",
    "\n",
    "        # Check conditions\n",
    "        if not required_ingredients.issubset(set(available_ingredients)):\n",
    "            continue\n",
    "        if \"tools\" in recipes.columns and not required_tools.issubset(set(available_tools)):\n",
    "            continue\n",
    "        if time_col and prep_time > max_time:\n",
    "            continue\n",
    "\n",
    "        filtered.append(recipe)\n",
    "\n",
    "    return pd.DataFrame(filtered).sort_values(by=time_col, ascending=True) if time_col else pd.DataFrame(filtered)\n",
    "\n",
    "# Example usage\n",
    "available_ingredients = {\"eggs\", \"flour\", \"milk\", \"butter\"}\n",
    "available_tools = {\"oven\", \"whisk\"}\n",
    "max_time = 30\n",
    "\n",
    "filtered_recipes = filter_recipes(datasets[\"RAW_recipes\"], available_ingredients, available_tools, max_time)\n",
    "print(\"\\nüîπ Filtered Recipes:\\n\", filtered_recipes.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule-Based Recipe Generation\n",
    "import random\n",
    "\n",
    "def generate_recipe(available_ingredients, available_tools, max_time, dataset):\n",
    "    \"\"\"Generates a new recipe based on available ingredients and constraints.\"\"\"\n",
    "    filtered = filter_recipes(dataset, available_ingredients, available_tools, max_time)\n",
    "    \n",
    "    if filtered.empty:\n",
    "        return \"‚ùå No valid recipes found.\"\n",
    "\n",
    "    # Pick a random recipe from filtered results\n",
    "    selected_recipe = filtered.sample(1).iloc[0]\n",
    "\n",
    "    # Format the output\n",
    "    return f\"\"\"\n",
    "    üçΩÔ∏è Recipe: {selected_recipe['name']}\n",
    "    üïí Time: {selected_recipe['minutes']} minutes\n",
    "    üõ†Ô∏è Tools: {', '.join(available_tools)}\n",
    "    üìù Ingredients: {', '.join(selected_recipe['ingredients'])}\n",
    "    üìú Steps: {selected_recipe['steps'] if 'steps' in selected_recipe else 'No steps available'}\n",
    "    \"\"\"\n",
    "\n",
    "# Example Usage\n",
    "print(generate_recipe({\"eggs\", \"flour\", \"milk\", \"butter\"}, {\"oven\", \"whisk\"}, 30, datasets[\"RAW_recipes\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AI-Based Recipe Generation (Python + NLP)\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load pre-trained NLP model (T5 is good for text generation)\n",
    "generator = pipeline(\"text-generation\", model=\"t5-small\")\n",
    "\n",
    "def generate_ai_recipe(available_ingredients, available_tools, max_time):\n",
    "    \"\"\"Generates a recipe using an AI model (GPT/T5).\"\"\"\n",
    "    \n",
    "    prompt = f\"Generate a recipe using:\\nIngredients: {', '.join(available_ingredients)}\\nTools: {', '.join(available_tools)}\\nMax Time: {max_time} minutes\"\n",
    "    \n",
    "    result = generator(prompt, max_length=150, num_return_sequences=1)\n",
    "    \n",
    "    return f\"üçΩÔ∏è AI-Generated Recipe:\\n{result[0]['generated_text']}\"\n",
    "\n",
    "# Example Usage\n",
    "print(generate_ai_recipe({\"eggs\", \"flour\", \"milk\", \"butter\"}, {\"oven\", \"whisk\"}, 30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Updated Rule-Based Recipe Generator (Fully Automated)\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "def get_best_dataset(datasets, available_ingredients, available_tools, max_time):\n",
    "    \"\"\"Automatically selects the dataset with the most matching recipes.\"\"\"\n",
    "    dataset_scores = {}\n",
    "\n",
    "    for name, dataset in datasets.items():\n",
    "        if \"ingredients\" in dataset.columns:\n",
    "            # Count recipes that match the ingredient and time constraints\n",
    "            filtered = filter_recipes(dataset, available_ingredients, available_tools, max_time)\n",
    "            dataset_scores[name] = len(filtered)\n",
    "\n",
    "    # Choose the dataset with the most valid recipes\n",
    "    best_dataset = max(dataset_scores, key=dataset_scores.get)\n",
    "\n",
    "    print(f\"\\n‚úÖ Using Best Dataset: {best_dataset} ({dataset_scores[best_dataset]} matching recipes)\")\n",
    "    return datasets[best_dataset]\n",
    "\n",
    "def generate_recipe(available_ingredients, available_tools, max_time, datasets):\n",
    "    \"\"\"Generates a new recipe based on available ingredients and constraints.\"\"\"\n",
    "\n",
    "    # Step 1: Automatically pick the best dataset\n",
    "    dataset = get_best_dataset(datasets, available_ingredients, available_tools, max_time)\n",
    "\n",
    "    # Step 2: Filter recipes\n",
    "    filtered = filter_recipes(dataset, available_ingredients, available_tools, max_time)\n",
    "\n",
    "    if filtered.empty:\n",
    "        return \"‚ùå No valid recipes found.\"\n",
    "\n",
    "    # Step 3: Select a random recipe\n",
    "    selected_recipe = filtered.sample(1).iloc[0]\n",
    "\n",
    "    # Step 4: Randomly swap or add an ingredient\n",
    "    ingredient_list = list(selected_recipe[\"ingredients\"])\n",
    "    if len(ingredient_list) > 2:\n",
    "        ingredient_list[random.randint(0, len(ingredient_list) - 1)] = random.choice(list(available_ingredients))\n",
    "\n",
    "    # Step 5: Format output\n",
    "    return f\"\"\"\n",
    "    üçΩÔ∏è **Generated Recipe:** {selected_recipe['name']} (Modified)\n",
    "    üïí **Time:** {selected_recipe['minutes']} minutes\n",
    "    üõ†Ô∏è **Tools:** {', '.join(available_tools)}\n",
    "    üìù **Ingredients:** {', '.join(ingredient_list)}\n",
    "    üìú **Steps:** {selected_recipe['steps'] if 'steps' in selected_recipe else 'No steps available'}\n",
    "    \"\"\"\n",
    "\n",
    "# Example Usage\n",
    "available_ingredients = {\"eggs\", \"flour\", \"milk\", \"butter\", \"chocolate\"}\n",
    "available_tools = {\"oven\", \"whisk\"}\n",
    "max_time = 30\n",
    "\n",
    "print(generate_recipe(available_ingredients, available_tools, max_time, datasets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Load datasets from Kaggle\n",
    "datasets = {\n",
    "    \"PP_recipes\": df1,\n",
    "    \"RAW_recipes\": df2,\n",
    "    \"Test_Recipes\": df3,\n",
    "    \"Train_Recipes\": df4\n",
    "}\n",
    "\n",
    "loaded_data = {}\n",
    "\n",
    "for name, file_path in datasets.items():\n",
    "    try:\n",
    "        loaded_data[name] = kagglehub.load_dataset(\n",
    "            KaggleDatasetAdapter.PANDAS,\n",
    "            \"shuyangli94/food-com-recipes-and-user-interactions\" if \"recipes\" in name else \"kaggle/recipe-ingredients-dataset\",\n",
    "            file_path\n",
    "        )\n",
    "        print(f\"‚úÖ Loaded {name} successfully. First 5 rows:\")\n",
    "        print(loaded_data[name].head())\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load {name}: {e}\")\n",
    "\n",
    "# Function to load datasets from local files (fallback method)\n",
    "def load_recipes(file_path):\n",
    "    \"\"\"Loads a recipe dataset from CSV or JSON.\"\"\"\n",
    "    try:\n",
    "        if file_path.endswith('.csv'):\n",
    "            return pd.read_csv(file_path)\n",
    "        elif file_path.endswith('.json'):\n",
    "            return pd.read_json(file_path)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Use CSV or JSON.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Recipe filtering function\n",
    "def filter_recipes(recipes, available_ingredients, available_tools, max_time):\n",
    "    \"\"\"Filters recipes based on available ingredients, kitchen tools, and time constraints.\"\"\"\n",
    "    if recipes is None or recipes.empty:\n",
    "        print(\"‚ùå No recipes available to filter.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    filtered = []\n",
    "\n",
    "    for _, recipe in recipes.iterrows():\n",
    "        # Handle missing values safely\n",
    "        required_ingredients = set(str(recipe.get('ingredients', '')).lower().split(', '))\n",
    "        required_tools = set(str(recipe.get('tools', '')).lower().split(', '))\n",
    "        prep_time = int(recipe.get('time', 0))  # Ensure time is an integer\n",
    "\n",
    "        # Check ingredient availability\n",
    "        if not required_ingredients.issubset(set(available_ingredients)):\n",
    "            continue\n",
    "\n",
    "        # Check kitchen tool availability\n",
    "        if not required_tools.issubset(set(available_tools)):\n",
    "            continue\n",
    "\n",
    "        # Check time constraint\n",
    "        if prep_time > max_time:\n",
    "            continue\n",
    "\n",
    "        filtered.append(recipe)\n",
    "\n",
    "    return pd.DataFrame(filtered).sort_values(by=\"time\", ascending=True)\n",
    "\n",
    "# Example Usage\n",
    "available_ingredients = {\"eggs\", \"flour\", \"milk\", \"butter\"}\n",
    "available_tools = {\"oven\", \"whisk\"}\n",
    "max_time = 30\n",
    "\n",
    "# Filter recipes using one of the loaded datasets (choose appropriately)\n",
    "if \"PP_recipes\" in loaded_data:\n",
    "    filtered_recipes = filter_recipes(loaded_data[\"PP_recipes\"], available_ingredients, available_tools, max_time)\n",
    "    print(\"Filtered Recipes:\\n\", filtered_recipes.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
